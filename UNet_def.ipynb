{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNet_def.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7dfee193a6e94c43856a6a2296d3f487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0b4a4da849994cac8e85b10711a63e32",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9bcc63a250d64f7b8d8c6bcdd931fa47",
              "IPY_MODEL_2076269be7cc41958829fafefdbe0943",
              "IPY_MODEL_6a7280d98a7c44ed9ba50cd69b7a32c4"
            ]
          }
        },
        "0b4a4da849994cac8e85b10711a63e32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9bcc63a250d64f7b8d8c6bcdd931fa47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9584278546ab477ba4d98c987ad76530",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_778aaa1c1f34404c87c78c5ef5222e16"
          }
        },
        "2076269be7cc41958829fafefdbe0943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ba04a6187d4f4353bdc0eed16feb1939",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e453bf9f36494ee0aa5c6b9761a3b3f0"
          }
        },
        "6a7280d98a7c44ed9ba50cd69b7a32c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4ca0ddd124814eb88050983146aa0642",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:07&lt;00:00, 29316218.19it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73f0fc1b0faf478aae6c8dec283084b3"
          }
        },
        "9584278546ab477ba4d98c987ad76530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "778aaa1c1f34404c87c78c5ef5222e16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba04a6187d4f4353bdc0eed16feb1939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e453bf9f36494ee0aa5c6b9761a3b3f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ca0ddd124814eb88050983146aa0642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73f0fc1b0faf478aae6c8dec283084b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT3lKrcl5lAv"
      },
      "source": [
        "# Computer vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF4hjFHf5lAx"
      },
      "source": [
        "## Librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOXc8EwE5lAy"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "partitions = ['train', 'val']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBI0tET25lAz"
      },
      "source": [
        "## Crear la base de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp-MCO6P5lAz"
      },
      "source": [
        "### Funciones para pre procesamiento "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0ocM9FC5lA0"
      },
      "source": [
        "train_transform = transforms.Compose(\n",
        "    [transforms.RandomCrop(32, padding=4),\n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.ToTensor()])#transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "\n",
        "test_transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])#transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "7dfee193a6e94c43856a6a2296d3f487",
            "0b4a4da849994cac8e85b10711a63e32",
            "9bcc63a250d64f7b8d8c6bcdd931fa47",
            "2076269be7cc41958829fafefdbe0943",
            "6a7280d98a7c44ed9ba50cd69b7a32c4",
            "9584278546ab477ba4d98c987ad76530",
            "778aaa1c1f34404c87c78c5ef5222e16",
            "ba04a6187d4f4353bdc0eed16feb1939",
            "e453bf9f36494ee0aa5c6b9761a3b3f0",
            "4ca0ddd124814eb88050983146aa0642",
            "73f0fc1b0faf478aae6c8dec283084b3"
          ]
        },
        "id": "QwZFttB45lA0",
        "outputId": "de6fe08b-4c19-414b-f8b0-a8bb15e00828"
      },
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=train_transform)\n",
        "train_set, val_set = torch.utils.data.random_split(trainset, [40000, 10000])\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=test_transform)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7dfee193a6e94c43856a6a2296d3f487",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIZ7X27k5lA1",
        "outputId": "38b32e4c-f47b-413b-9558-5f3209d65207"
      },
      "source": [
        "len(trainset), len(val_set), len(testset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaDP0LoL5lA1"
      },
      "source": [
        "### Cargar los datos "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBQewXy95lA2"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(train_set, batch_size=1,\n",
        "                                          shuffle=True)\n",
        "valLoader = torch.utils.data.DataLoader(val_set, batch_size=1,\n",
        "                                          shuffle=True)\n",
        "dataloaders = {'train': trainloader,\\\n",
        "              'val': valLoader}\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
        "                                         shuffle=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX3vixSC5lA2"
      },
      "source": [
        "for data in trainloader:\n",
        "    inputs, labels = data\n",
        "   # print(inputs.shape)\n",
        "    data_toDisplay = np.transpose(torchvision.utils.make_grid(inputs), (1, 2, 0))\n",
        "   # plt.imshow(data_toDisplay)\n",
        "   # plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHaxPQe0uHAT"
      },
      "source": [
        "# **Modelo UNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JonOFiWn8o-"
      },
      "source": [
        "class UNet(nn.Module):\n",
        "    def contracting_block(self, in_channels, out_channels, kernel_size=3):\n",
        "       # \"\"\"\n",
        "       # This function creates one contracting block\n",
        "       # \"\"\"\n",
        "        block = torch.nn.Sequential(\n",
        "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels),\n",
        "                    torch.nn.ReLU(),\n",
        "                  #  torch.nn.BatchNorm2d(out_channels),\n",
        "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels),\n",
        "                    torch.nn.ReLU(),\n",
        "                  #  torch.nn.BatchNorm2d(out_channels),\n",
        "                )\n",
        "        return block\n",
        "\n",
        "    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n",
        "       #  \"\"\"\n",
        "       # This function creates one expansive block\n",
        "       # \"\"\"\n",
        "            block = torch.nn.Sequential(\n",
        "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel),\n",
        "                    torch.nn.ReLU(),\n",
        "                   # torch.nn.BatchNorm2d(mid_channel),\n",
        "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel),\n",
        "                    torch.nn.ReLU(),\n",
        "                   # torch.nn.BatchNorm2d(mid_channel),\n",
        "                    torch.nn.ConvTranspose2d(in_channels=mid_channel, out_channels=out_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
        "                    )\n",
        "            return  block\n",
        "\n",
        "    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n",
        "       #  \"\"\"\n",
        "       # This returns final block\n",
        "       # \"\"\"\n",
        "        block = torch.nn.Sequential(\n",
        "                torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel),\n",
        "                torch.nn.ReLU(),\n",
        "               # torch.nn.BatchNorm2d(mid_channel),\n",
        "                torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel),\n",
        "                torch.nn.ReLU(),\n",
        "               # torch.nn.BatchNorm2d(mid_channel),\n",
        "                torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=1),\n",
        "                torch.nn.ReLU(),\n",
        "               # torch.nn.BatchNorm2d(out_channels),\n",
        "                )\n",
        "        return  block\n",
        "\n",
        "    def __init__(self, in_channel, out_channel):\n",
        "        super(UNet, self).__init__()\n",
        "        #Encode\n",
        "        self.conv_encode1 = self.contracting_block(in_channels=in_channel, out_channels=64)\n",
        "        self.conv_maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv_encode2 = self.contracting_block(64, 128)\n",
        "        self.conv_maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv_encode3 = self.contracting_block(128, 256)\n",
        "        self.conv_maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "        # Bottleneck\n",
        "        self.bottleneck = torch.nn.Sequential(\n",
        "                            torch.nn.Conv2d(kernel_size=3, in_channels=256, out_channels=512),\n",
        "                            torch.nn.ReLU(),\n",
        "                          #  torch.nn.BatchNorm2d(512),\n",
        "                            torch.nn.Conv2d(kernel_size=3, in_channels=512, out_channels=512),\n",
        "                            torch.nn.ReLU(),\n",
        "                          #  torch.nn.BatchNorm2d(512),\n",
        "                            torch.nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
        "                            )\n",
        "        # Decode\n",
        "        self.conv_decode3 = self.expansive_block(512, 256, 128)\n",
        "        self.conv_decode2 = self.expansive_block(256, 128, 64)\n",
        "        self.final_layer = self.final_block(128, 64, out_channel)\n",
        "\n",
        "    def crop_and_concat(self, upsampled, bypass, crop=False):\n",
        "      #  \"\"\"\n",
        "      #  This layer crop the layer from contraction block and concat it with expansive block vector\n",
        "      #  \"\"\"\n",
        "        if crop:\n",
        "            c = (bypass.size()[2] - upsampled.size()[2]) // 2\n",
        "            bypass = F.pad(bypass, (-c, -c, -c, -c))\n",
        "        return torch.cat((upsampled, bypass), 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encode\n",
        "        encode_block1 = self.conv_encode1(x)\n",
        "        encode_pool1 = self.conv_maxpool1(encode_block1)\n",
        "        encode_block2 = self.conv_encode2(encode_pool1)\n",
        "        encode_pool2 = self.conv_maxpool2(encode_block2)\n",
        "        encode_block3 = self.conv_encode3(encode_pool2)\n",
        "        encode_pool3 = self.conv_maxpool3(encode_block3)\n",
        "        # Bottleneck\n",
        "        bottleneck1 = self.bottleneck(encode_pool3)\n",
        "        # Decode\n",
        "        decode_block3 = self.crop_and_concat(bottleneck1, encode_block3, crop=True)\n",
        "        cat_layer2 = self.conv_decode3(decode_block3)\n",
        "        decode_block2 = self.crop_and_concat(cat_layer2, encode_block2, crop=True)\n",
        "        cat_layer1 = self.conv_decode2(decode_block2)\n",
        "        decode_block1 = self.crop_and_concat(cat_layer1, encode_block1, crop=False)\n",
        "        final_layer = self.final_layer(decode_block1)\n",
        "        return  final_layer"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47uVHp-YpGAf"
      },
      "source": [
        "net = UNet(in_channel= 1,out_channel=1)\n",
        "#unet = unet.cuda()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmnLVvWqpoEm"
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr = 0.01, momentum=0.99)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR1boKDAptcA"
      },
      "source": [
        "# **Entrenamiento**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "SHjOuTZmtd3o",
        "outputId": "4135f459-72d2-489b-88ad-061941982581"
      },
      "source": [
        "for epoch in range(10):  # \n",
        "    for phase in partitions:\n",
        "        \n",
        "        if phase == partitions[0]:\n",
        "            net.train()\n",
        "        else:\n",
        "            net.eval() \n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(dataloaders[phase]):\n",
        "            # Obtener los datos\n",
        "            inputs, labels = data\n",
        "\n",
        "            \n",
        "            # Inicializar los gradientes \n",
        "            optimizer.zero_grad()\n",
        "            with torch.set_grad_enabled(phase == partitions[0]):\n",
        "                # forward + backward + optimize\n",
        "                outputs = net(inputs)\n",
        "                loss = criterion(outputs, labels.view(1,-1))\n",
        "                if phase == partitions[0]: \n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "        loss_epoch =  running_loss / float(len(dataloaders[phase]))\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, loss_epoch))\n",
        "#                 running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-10c000737d05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-3e4a97cc1f2d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# Encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mencode_block1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_encode1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mencode_pool1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_maxpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode_block1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mencode_block2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_encode2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode_pool1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 440\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 1, 3, 3], expected input[1, 3, 32, 32] to have 1 channels, but got 3 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "X6oPpm-zJS2b",
        "outputId": "525fcd1e-f4d4-4d25-905f-08649a25b3a1"
      },
      "source": [
        "n_epochs = 8 # you may increase this number to train a final model\n",
        "\n",
        "valid_loss_min = np.Inf # track change in validation loss\n",
        "\n",
        "for epoch in range(1, n_epochs+1):\n",
        "\n",
        "    # keep track of training and validation loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "   \n",
        "    # train the model \n",
        "   \n",
        "    net.train()\n",
        "    for data, target in trainloader:\n",
        "       \n",
        "        #data, target = data.cuda(), target.cuda()\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = net(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "    \n",
        "    # validate the model \n",
        "   \n",
        "    net.eval()\n",
        "    for data, target in valLoader:\n",
        "        \n",
        "        data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = net(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average validation loss \n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "    \n",
        "    # calculate average losses\n",
        "    train_loss = train_loss/len(trainloader.dataset)\n",
        "    valid_loss = valid_loss/len(validLoader.dataset)\n",
        "        \n",
        "    # print training/validation statistics \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch, train_loss, valid_loss))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(net.state_dict(), 'model_cifar.pt')\n",
        "        valid_loss_min = valid_loss"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-212b569a0fe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# forward pass: compute predicted outputs by passing inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m# calculate the batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-3e4a97cc1f2d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# Encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mencode_block1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_encode1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mencode_pool1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_maxpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode_block1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mencode_block2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_encode2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode_pool1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 440\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 1, 3, 3], expected input[1, 3, 32, 32] to have 1 channels, but got 3 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Rk1y5ZkJSbF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkj62nsRzKkV"
      },
      "source": [
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih65BkE8zLWY"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzG-7qfPzRCx"
      },
      "source": [
        "## Predicción"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRbudCoJxibC"
      },
      "source": [
        "\n",
        "\n",
        "# Predicción\n",
        "\n",
        "for data in testloader:\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.cuda()\n",
        "    labels = labels.cuda()\n",
        "#     print(inputs.shape)\n",
        "  #  data_toDisplay = np.transpose(torchvision.utils.make_grid(inputs.cuda()), (1, 2, 0))\n",
        "    print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(1)))\n",
        "    fig = plt.figure(figsize=(2,2))\n",
        "    plt.imshow(data_toDisplay)\n",
        "    plt.show()\n",
        "    \n",
        "    outputs = net(inputs.cuda())\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(1)))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtoKSevXxjgZ"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5hNT2ljxkwJ"
      },
      "source": [
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
        "                                                   accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7PXBLZ5JGTh"
      },
      "source": [
        "# **Data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR319wiRJJZ_"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "from keras import backend as K\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEvkCkXYJsX6",
        "outputId": "1b1a41e5-6585-49be-87dc-6003ddea7360"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 20s 0us/step\n",
            "170508288/170498071 [==============================] - 20s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhWicz7HJtdb"
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IOcvQygJw7B"
      },
      "source": [
        "Estandarización"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7UKospHJy_q"
      },
      "source": [
        "X_train/=255\n",
        "X_test/=255"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN5VMFX6J1l7"
      },
      "source": [
        "Rotación de las imágenes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "EFocMeyvJzG6",
        "outputId": "3ea6e3bf-91c8-4a07-856d-0351612c6bc0"
      },
      "source": [
        "datagen = ImageDataGenerator(rotation_range=359)\n",
        "datagen.fit(X_train)\n",
        "\n",
        "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=4, seed=499):\n",
        "  for i in range(0,4):\n",
        "    pyplot.subplot(220 +1 +i)\n",
        "    pyplot.imshow(X_batch[i])\n",
        "  pyplot.show()\n",
        "  break"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3hsncrNJ5-A"
      },
      "source": [
        "Desplazamiento vertical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPnJ27y0KBcg"
      },
      "source": [
        "datagen = ImageDataGenerator(height_shift_range=0.5)\n",
        "datagen.fit(X_train)\n",
        "\n",
        "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=4, seed=499):\n",
        "  for i in range(0,4):\n",
        "    pyplot.subplot(220 +1 +i)\n",
        "    pyplot.imshow(X_batch[i])\n",
        "  pyplot.show()\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwKFN3ccKKcR"
      },
      "source": [
        "Featurewise Center"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn7vI6GFKJ8R"
      },
      "source": [
        "datagen = ImageDataGenerator(featurewise_center=True)\n",
        "datagen.fit(X_train)\n",
        "\n",
        "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=4, seed=499):\n",
        "  for i in range(0,4):\n",
        "    pyplot.subplot(220 +1 +i)\n",
        "    pyplot.imshow(X_batch[i])\n",
        "  pyplot.show()\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuIEokh2KTAq"
      },
      "source": [
        "Samplewise Center"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNikwtaFKRdq"
      },
      "source": [
        "datagen = ImageDataGenerator(samplewise_center=True)\n",
        "datagen.fit(X_train)\n",
        "\n",
        "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=4, seed=499):\n",
        "  for i in range(0,4):\n",
        "    pyplot.subplot(220 +1 +i)\n",
        "    pyplot.imshow(X_batch[i])\n",
        "  pyplot.show()\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PF3ptiuKVg5"
      },
      "source": [
        "Featurewise std_normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLuLOD4TKVvh"
      },
      "source": [
        "datagen = ImageDataGenerator(featurewise_std_normalization=True)\n",
        "datagen.fit(X_train)\n",
        "\n",
        "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=4, seed=499):\n",
        "  for i in range(0,4):\n",
        "    pyplot.subplot(220 +1 +i)\n",
        "    pyplot.imshow(X_batch[i])\n",
        "  pyplot.show()\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gMR6xZPKZIy"
      },
      "source": [
        "Samplewise std_normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q69sIb-KKaV1"
      },
      "source": [
        "datagen = ImageDataGenerator(samplewise_std_normalization=True)\n",
        "datagen.fit(X_train)\n",
        "\n",
        "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=4, seed=499):\n",
        "  for i in range(0,4):\n",
        "    pyplot.subplot(220 +1 +i)\n",
        "    pyplot.imshow(X_batch[i])\n",
        "  pyplot.show()\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB4Bezn2Kgv0"
      },
      "source": [
        "Zca Whitening"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0DVWWtxKfSU"
      },
      "source": [
        "datagen = ImageDataGenerator(zca_whitening=True)\n",
        "datagen.fit(X_train)\n",
        "\n",
        "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=4, seed=499):\n",
        "  for i in range(0,4):\n",
        "    pyplot.subplot(220 +1 +i)\n",
        "    pyplot.imshow(X_batch[i])\n",
        "  pyplot.show()\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAm0yAr9Kje6"
      },
      "source": [
        "Zoom Range"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fItSxa-fKj3c"
      },
      "source": [
        "datagen = ImageDataGenerator(zoom_range=0.3)\n",
        "datagen.fit(X_train)\n",
        "\n",
        "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=4, seed=499):\n",
        "  for i in range(0,4):\n",
        "    pyplot.subplot(220 +1 +i)\n",
        "    pyplot.imshow(X_batch[i])\n",
        "  pyplot.show()\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKIwcHelK3xz"
      },
      "source": [
        "import os\n",
        "\n",
        "import scipy.io\n",
        "from skimage.transform import resize\n",
        "from tqdm import tqdm, trange\n",
        "import gc\n",
        "import torch\n",
        "import sys\n",
        "gc.collect()\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "def thresh(x):\n",
        "    if x == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "thresh = np.vectorize(thresh, otypes=[np.float])\n",
        "\n",
        "def create_dataset(paths, width_in, height_in, width_out, height_out, data_indexes, mat):\n",
        "    x = []\n",
        "    y = []\n",
        "    for path in tqdm(paths):\n",
        "        mat = scipy.io.loadmat(path)\n",
        "        img_tensor = mat['images']\n",
        "        fluid_tensor = mat['manualFluid1']\n",
        "        img_array = np.transpose(img_tensor, (2, 0 ,1)) / 255\n",
        "        img_array = resize(img_array, (img_array.shape[0], width_in, height_in))\n",
        "        fluid_array = np.transpose(fluid_tensor, (2, 0 ,1))\n",
        "        fluid_array = thresh(fluid_array)\n",
        "        fluid_array  = resize(fluid_array, (fluid_array .shape[0], width_out, height_out))\n",
        "\n",
        "        for idx in data_indexes:\n",
        "            x += [np.expand_dims(img_array[idx], 0)]\n",
        "            y += [np.expand_dims(fluid_array[idx], 0)]\n",
        "    return np.array(x), np.array(y)\n",
        "\n",
        "def get_dataset(width_in, height_in, width_out, height_out):\n",
        "    input_path = os.path.join('2015_BOE_Chiu')\n",
        "    subject_path = [os.path.join(input_path, 'Subject_0{}.mat'.format(i)) for i in range(1, 10)] + [os.path.join(input_path, 'Subject_10.mat')]\n",
        "    #subject_path = [os.path.join(input_path, 'Subject_0{}.mat'.format(i)) for i in range(1, 3)]\n",
        "    m = len(subject_path)\n",
        "    data_indexes = [10, 15, 20, 25, 28, 30, 32, 35, 40, 45, 50]\n",
        "    mat = scipy.io.loadmat(subject_path[0])\n",
        "    img_tensor = mat['images']\n",
        "    manual_fluid_tensor_1 = mat['manualFluid1']\n",
        "    img_array = np.transpose(img_tensor, (2, 0, 1))\n",
        "    manual_fluid_array = np.transpose(manual_fluid_tensor_1, (2, 0, 1))\n",
        "    x_train, y_train = create_dataset(subject_path[:m-1], width_in, height_in, width_out, height_out, data_indexes, mat)\n",
        "    x_val, y_val = create_dataset(subject_path[m-1:], width_in, height_in, width_out, height_out, data_indexes, mat)\n",
        "    return x_train, y_train,x_val,y_val\n",
        "\n",
        "def train_step(inputs, labels, optimizer, criterion, unet, width_out, height_out):\n",
        "    optimizer.zero_grad()\n",
        "    # forward + backward + optimize\n",
        "    outputs = unet(inputs)\n",
        "    # outputs.shape =(batch_size, n_classes, img_cols, img_rows)\n",
        "    outputs = outputs.permute(0, 2, 3, 1)\n",
        "    # outputs.shape =(batch_size, img_cols, img_rows, n_classes)\n",
        "    m = outputs.shape[0]\n",
        "    outputs = outputs.resize(m*width_out*height_out, 2)\n",
        "    labels = labels.resize(m*width_out*height_out)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss\n",
        "\n",
        "def get_val_loss(x_val, y_val, width_out, height_out, unet):\n",
        "    x_val = torch.from_numpy(x_val).float()\n",
        "    y_val = torch.from_numpy(y_val).long()\n",
        "    if use_gpu:\n",
        "        x_val = x_val.cuda()\n",
        "        y_val = y_val.cuda()\n",
        "    m = x_val.shape[0]\n",
        "    outputs = unet(x_val)\n",
        "    # outputs.shape =(batch_size, n_classes, img_cols, img_rows) \n",
        "    outputs = outputs.permute(0, 2, 3, 1)\n",
        "    # outputs.shape =(batch_size, img_cols, img_rows, n_classes) \n",
        "    outputs = outputs.resize(m*width_out*height_out, 2)\n",
        "    labels = y_val.resize(m*width_out*height_out)\n",
        "    loss = F.cross_entropy(outputs, labels)\n",
        "    return loss.data\n",
        "\n",
        "def train(unet, batch_size, epochs, epoch_lapse, threshold, learning_rate, criterion, optimizer, x_train, y_train, x_val, y_val, width_out, height_out):\n",
        "    epoch_iter = np.ceil(x_train.shape[0] / batch_size).astype(int)\n",
        "    t = trange(epochs, leave=True)\n",
        "    for _ in t:\n",
        "        total_loss = 0\n",
        "        for i in range(epoch_iter):\n",
        "            batch_train_x = torch.from_numpy(x_train[i * batch_size : (i + 1) * batch_size]).float()\n",
        "            batch_train_y = torch.from_numpy(y_train[i * batch_size : (i + 1) * batch_size]).long()\n",
        "            if use_gpu:\n",
        "                batch_train_x = batch_train_x.cuda()\n",
        "                batch_train_y = batch_train_y.cuda()\n",
        "            batch_loss = train_step(batch_train_x , batch_train_y, optimizer, criterion, unet, width_out, height_out)\n",
        "            total_loss += batch_loss\n",
        "        if (_+1) % epoch_lapse == 0:\n",
        "            val_loss = get_val_loss(x_val, y_val, width_out, height_out, unet)\n",
        "            print(\"Total loss in epoch %f : %f and validation loss : %f\" %(_+1, total_loss, val_loss))\n",
        "    gc.collect()\n",
        "\n",
        "def plot_examples(unet, datax, datay, num_examples=3):\n",
        "    fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(18,4*num_examples))\n",
        "    m = datax.shape[0]\n",
        "    for row_num in range(num_examples):\n",
        "        image_indx = np.random.randint(m)\n",
        "        image_arr = unet(torch.from_numpy(datax[image_indx:image_indx+1]).float().cuda()).squeeze(0).detach().cpu().numpy()\n",
        "        ax[row_num][0].imshow(np.transpose(datax[image_indx], (1,2,0))[:,:,0])\n",
        "        ax[row_num][1].imshow(np.transpose(image_arr, (1,2,0))[:,:,0])\n",
        "        ax[row_num][2].imshow(image_arr.argmax(0))\n",
        "        ax[row_num][3].imshow(np.transpose(datay[image_indx], (1,2,0))[:,:,0])\n",
        "    plt.show()\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "8235MqoPLaxu",
        "outputId": "95d44b8b-9859-45e2-e13f-e919b2543606"
      },
      "source": [
        "    width_in = 284\n",
        "    height_in = 284\n",
        "    width_out = 196\n",
        "    height_out = 196\n",
        "    PATH = './unet.pt'\n",
        "    #x_train, y_train, x_val, y_val = get_dataset(width_in, height_in, width_out, height_out)\n",
        "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "    batch_size = 3\n",
        "    epochs = 1\n",
        "    epoch_lapse = 50\n",
        "    threshold = 0.5\n",
        "    learning_rate = 0.01\n",
        "    #net = UNet(in_channel=1,out_channel=2)\n",
        "    if use_gpu:\n",
        "        unet = unet.cuda()\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr = 0.01, momentum=0.99)\n",
        "    train(net, batch_size, epochs, epoch_lapse, threshold, learning_rate, criterion, optimizer, X_train, y_train, X_test, y_test, width_out, height_out)\n",
        "    print(net.eval())\n",
        "    plot_examples(net, X_train, y_train)\n",
        "    plot_examples(net, X_test, y_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-090c0ba2d47f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_lapse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mplot_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-f4dd4679954c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(unet, batch_size, epochs, epoch_lapse, threshold, learning_rate, criterion, optimizer, x_train, y_train, x_val, y_val, width_out, height_out)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mbatch_train_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_train_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mbatch_train_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_train_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_train_x\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_train_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch_lapse\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-f4dd4679954c>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(inputs, labels, optimizer, criterion, unet, width_out, height_out)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# outputs.shape =(batch_size, n_classes, img_cols, img_rows)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-3e4a97cc1f2d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# Encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mencode_block1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_encode1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mencode_pool1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_maxpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode_block1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mencode_block2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_encode2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode_pool1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    439\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 440\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 1, 3, 3], expected input[3, 32, 32, 3] to have 1 channels, but got 32 channels instead"
          ]
        }
      ]
    }
  ]
}